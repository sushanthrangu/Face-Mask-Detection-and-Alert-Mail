{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_validate\n",
    "import os as os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.28000000e+02 3.02000000e+02 3.00000000e+00 5.83979388e-01\n",
      "  1.00503359e-01 1.00503359e-01 1.00503359e-01 3.62150068e-01\n",
      "  2.00000000e+00 1.66500000e+02 1.13550000e+04]\n",
      " [2.15910000e+04 1.17900000e+03 2.28000000e+02 9.04565058e+01\n",
      "  2.57982918e+01 5.70932865e+00 1.11115882e+00 5.17662002e+00\n",
      "  3.69000000e+02 1.84429708e+01 1.33036605e+03]\n",
      " [7.31000000e+03 1.21500000e+03 1.01000000e+02 2.55036445e+01\n",
      "  9.55634744e+00 5.36151928e+00 5.91205607e-01 3.58971842e+00\n",
      "  9.50000000e+01 6.89278351e+01 5.99989691e+03]\n",
      " [2.00000000e+01 7.00000000e+00 2.00000000e+00 7.69082373e+00\n",
      "  2.77305641e-01 1.33150798e+00 1.00503359e-01 2.83062680e+00\n",
      "  6.00000000e+00 2.00000000e+00 9.61666667e+01]\n",
      " [4.55890000e+04 8.62000000e+02 2.64100000e+03 1.48854279e+02\n",
      "  3.69988839e+01 2.78817679e+01 3.33349180e+00 2.38612817e+01\n",
      "  5.51000000e+02 1.27404293e+02 2.83384794e+03]\n",
      " [2.85735000e+05 2.76251000e+05 3.41700000e+03 1.93275815e+01\n",
      "  7.29201558e+00 1.00503359e-01 1.00503359e-01 1.00503359e-01\n",
      "  6.00000000e+01 4.48064516e+01 4.14425806e+03]\n",
      " [2.85735000e+05 2.76251000e+05 3.41700000e+03 1.93275815e+01\n",
      "  7.29201558e+00 1.00503359e-01 1.00503359e-01 1.00503359e-01\n",
      "  6.00000000e+01 4.48064516e+01 4.14425806e+03]\n",
      " [9.51200000e+03 1.20000000e+01 2.13000000e+02 5.21670685e+01\n",
      "  2.31822884e+01 3.62150068e-01 1.00503359e-01 6.80604526e+00\n",
      "  1.95000000e+02 1.16785714e+01 5.64040816e+02]\n",
      " [2.27387100e+06 4.52400000e+03 1.19460000e+04 6.78240534e+03\n",
      "  2.94452425e+03 1.29557233e+01 2.79186098e+00 6.62062083e+01\n",
      "  2.16780000e+04 6.85936431e+00 1.11320202e+03]\n",
      " [1.82598000e+05 1.40200000e+03 3.83100000e+03 1.45844910e+02\n",
      "  7.40029576e+01 2.35491893e+01 1.00503359e-01 1.59532426e+01\n",
      "  5.67000000e+02 2.76496516e+02 8.03806620e+03]]\n",
      "[0 0 0 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###########################\n",
    "# LOADING TRAINING DATA\n",
    "###########################\n",
    "os.chdir('C:/Users/Mrida/Documents/Python/who-is-more-influential-master/Original Dataset')\n",
    "trainfile = open('train.csv')\n",
    "for line in trainfile:\n",
    "    header = line.rstrip().split(',')\n",
    "    break\n",
    "\n",
    "y_train = []\n",
    "X_train_A = []\n",
    "X_train_B = []\n",
    "\n",
    "for line in trainfile:\n",
    "    splitted = line.rstrip().split(',')\n",
    "    label = int(splitted[0])\n",
    "    A_features = [float(item) for item in splitted[1:12]]\n",
    "    B_features = [float(item) for item in splitted[12:]]\n",
    "    y_train.append(label)\n",
    "    X_train_A.append(A_features)\n",
    "    X_train_B.append(B_features)\n",
    "trainfile.close()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "X_train_A = np.array(X_train_A)\n",
    "X_train_B = np.array(X_train_B)\n",
    "print(X_train_A[0:10])\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(x):\n",
    "    return np.log(1+x)\n",
    "    #x = (x - np.mean(x,axis = 0))/np.std(x,axis = 0) \n",
    "    #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mrida\\anaconda3\\envs\\tp\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Support vector Machine Accuracy******************\n",
      "SVM Accuracy: 0.9289610460388085\n",
      "Top Five Prediction Results\n",
      "[[0.17530098]\n",
      " [0.16676802]\n",
      " [0.53671888]\n",
      " [0.17526201]\n",
      " [0.84481085]\n",
      " [0.39194637]\n",
      " [0.15558249]\n",
      " [0.39859321]\n",
      " [0.82701269]\n",
      " [0.22801191]]\n"
     ]
    }
   ],
   "source": [
    "X_train = transform_features(X_train_A) - transform_features(X_train_B)\n",
    "model=svm.SVC(probability=True);\n",
    "\n",
    "C = 1.0  # SVM regularization parameter\n",
    " \n",
    "model = svm.SVC(kernel='rbf', C=C, probability=True).fit(X_train, y_train)  \n",
    "p_train = model.predict_proba(X_train)\n",
    "p_train = p_train[:,1:2]\n",
    "precision, recall, thresholds=precision_recall_curve(y_train,p_train[:,0])\n",
    " \n",
    "print(\"******************Support vector Machine Accuracy******************\")\n",
    " \n",
    "print('SVM Accuracy:',roc_auc_score(y_train,p_train[:,0]))\n",
    "print(\"Top Five Prediction Results\")\n",
    "print(p_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************Logistic Regression Accuracy******************\n",
      "Logistic Regression Accuracy: 0.8630826810670553\n",
      "Top Five Prediction Results\n",
      "[[0.07308298]\n",
      " [0.34484905]\n",
      " [0.67473849]\n",
      " [0.02235788]\n",
      " [0.79521737]\n",
      " [0.61478659]\n",
      " [0.29782152]\n",
      " [0.35229926]\n",
      " [0.59178693]\n",
      " [0.42840826]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mrida\\anaconda3\\envs\\tp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model2=linear_model.LogisticRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "# Logistic regression # \n",
    "p_train1 = model2.predict_proba(X_train) \n",
    "p_train1 = p_train1[:,1:2]\n",
    "precision, recall, thresholds=precision_recall_curve(y_train,p_train1[:,0])\n",
    " \n",
    "print(\"******************Logistic Regression Accuracy******************\")\n",
    " \n",
    "print('Logistic Regression Accuracy:',roc_auc_score(y_train,p_train1[:,0]))\n",
    "print(\"Top Five Prediction Results\")\n",
    "print(p_train1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Five Prediction Results\n",
      "[[0.19571401]\n",
      " [0.10218223]\n",
      " [0.20105596]\n",
      " [0.23407099]\n",
      " [0.72194551]\n",
      " [0.17988734]\n",
      " [0.78903648]\n",
      " [0.78504206]\n",
      " [0.19336028]\n",
      " [0.77682522]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################\n",
    "# READING TEST DATA\n",
    "###########################\n",
    "\n",
    "testfile = open('C:\\\\Users\\\\Mrida\\\\Documents\\\\Python\\\\who-is-more-influential-master\\\\Original Dataset\\\\test.csv')\n",
    "#ignore the test header\n",
    "for line in testfile:\n",
    "    break\n",
    "\n",
    "X_test_A = []\n",
    "X_test_B = []\n",
    "for line in testfile:\n",
    "    splitted = line.rstrip().split(',')\n",
    "    A_features = [float(item) for item in splitted[0:11]]\n",
    "    B_features = [float(item) for item in splitted[11:]]\n",
    "    X_test_A.append(A_features)\n",
    "    X_test_B.append(B_features)\n",
    "testfile.close()\n",
    "\n",
    "X_test_A = np.array(X_test_A)\n",
    "X_test_B = np.array(X_test_B)\n",
    "\n",
    "# transform features in the same way as for training to ensure consistency\n",
    "X_test = transform_features(X_test_A) - transform_features(X_test_B)\n",
    "\n",
    "# compute probabilistic predictions\n",
    "p_test = model.predict_proba(X_test)\n",
    "#only need the probability of the 1 class\n",
    "p_test = p_test[:,1:2]\n",
    "print(\"Top Five Prediction Results\")\n",
    "print(p_test[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most influence Users data is Stored in CSV File\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################\n",
    "# WRITING SUBMISSION FILE\n",
    "###########################\n",
    "predfile = open('predictions.csv','w+')\n",
    "predfile.write('Id,Choice\\n')\n",
    "i=1;\n",
    "for line in p_test:\n",
    "    x=str(i)+','+str(line[0])\n",
    "    predfile.write(x)\n",
    "    predfile.write('\\n')\n",
    "    i=i+1\n",
    "\n",
    "predfile.close()\n",
    "print(\" Most influence Users data is Stored in CSV File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
